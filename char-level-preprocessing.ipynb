{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime for this cell in seconds:  6.048093795776367\n",
      "Corpus length in words:  23548408\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import os\n",
    "from keras.layers import Dense, Dropout, Activation, LSTM, Bidirectional, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from numpy.random import seed\n",
    "import numpy as np\n",
    "import jieba\n",
    "import time\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "seed(1)\n",
    "# tf.random.set_seed(2)\n",
    "punc = \"！？｡。＂＃＄％＆＇（）＊＋，－／：；＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､、〃》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘’‛“”„‟…‧﹏.《》（）+-=()\"\"''/=\"\n",
    "\n",
    "# skipped directories\n",
    "# SKIP = [\"0\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"]\n",
    "SKIP = [\"0\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\", \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\", \"v\", \"w\", \"x\", \"y\", \"z\"]\n",
    "# SKIP = []\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "def get_all_items(root: pathlib.Path, exclude):\n",
    "    itemList = []\n",
    "    for item in root.iterdir():\n",
    "        if item.name in exclude:\n",
    "            continue\n",
    "        if item.is_dir():\n",
    "            itemList.append(get_all_items(item, []))\n",
    "            continue\n",
    "        itemList.append(item)\n",
    "    return itemList\n",
    "\n",
    "\n",
    "# begin preprocessing\n",
    "largeDir = pathlib.Path(\"./Books\")\n",
    "# largeDir = pathlib.Path(\"./Books\")\n",
    "BookList = get_all_items(largeDir, SKIP)\n",
    "BookList = [item for sublist in BookList for item in sublist]\n",
    "\n",
    "\n",
    "# clean the dataset\n",
    "# for path in BookList:\n",
    "#     print(path)\n",
    "#     file = open(path, 'r')\n",
    "#     try:\n",
    "#         fileStr = file.read()\n",
    "#     except UnicodeDecodeError as error:\n",
    "#         file.close()\n",
    "#         os.remove(path)\n",
    "#     continue\n",
    "\n",
    "bigString = \"\"\n",
    "\n",
    "for path in BookList:\n",
    "    with open(path, 'r', encoding='gbk') as fiction:\n",
    "        bigString += fiction.read()\n",
    "\n",
    "# methods to strip punctuation and symbols\n",
    "# bigString = re.sub(r\"[%s]+\" %punc, \"\", bigString)\n",
    "bigString = re.sub(r'[^\\w\\s]', '', bigString)\n",
    "cleaned = re.sub(r'_','', bigString)\n",
    "cleaned1 = re.sub(r'(\\n+)', '', cleaned)\n",
    "\n",
    "# list of the words in their original order\n",
    "# allTokens = jieba.lcut(cleaned1, cut_all=False)\n",
    "allTokens = [*cleaned1]\n",
    "t2 = time.time()\n",
    "print(\"Runtime for this cell in seconds: \", t2 - t1)\n",
    "print(\"Corpus length in words: \", len(allTokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Unique words before filter:  5146\n",
      "To reduce vocab size, neglect words with appearances <  1023\n",
      "To reduce vocab size, neglect words with appearances >  50000000\n",
      "Unique words after filter:  1687\n"
     ]
    }
   ],
   "source": [
    "minFreq = 1023\n",
    "maxFreq = 50000000\n",
    "wordFreq = {}\n",
    "for token in allTokens:\n",
    "    wordFreq[token] = wordFreq.get(token, 0) + 1\n",
    "\n",
    "skipWords = set()\n",
    "u = 0\n",
    "for k, v in wordFreq.items():\n",
    "    # if 1000 > wordFreq[k] > 0:\n",
    "    #     u += wordFreq[k]\n",
    "    if wordFreq[k] < minFreq or wordFreq[k] > maxFreq:\n",
    "        skipWords.add(k)\n",
    "    elif k.isascii():\n",
    "        skipWords.add(k)\n",
    "\n",
    "print(u)\n",
    "# skipWords.remove(\"\\n\")\n",
    "skipWords.remove(\" \")\n",
    "skipWords.add(\"\\u3000\")\n",
    "words = set(allTokens)\n",
    "print(\"Unique words before filter: \", len(words))\n",
    "print(\"To reduce vocab size, neglect words with appearances < \", minFreq)\n",
    "print(\"To reduce vocab size, neglect words with appearances > \", maxFreq)\n",
    "words = sorted(set(words) - skipWords)\n",
    "print(\"Unique words after filter: \", len(words))\n",
    "\n",
    "word_indices = dict((c, i) for i, c in enumerate(words))\n",
    "indices_word = dict((i, c) for i, c in enumerate(words))\n",
    "class_weights = dict((word_indices[word],1/wordFreq[word]) for word in words)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '一', '丁', '七', '万', '丈', '三', '上', '下', '不', '与', '专', '且', '世', '业', '东', '丝', '丢', '两', '严', '个', '丫', '中', '丰', '临', '丹', '为', '主', '丽', '举', '乃', '久', '么', '义', '之', '乌', '乎', '乐', '乔', '乖', '乘', '九', '也', '习', '书', '买', '乱', '了', '争', '事', '二', '于', '亏', '云', '互', '五', '亚', '些', '亡', '交', '产', '享', '京', '亮', '亲', '人', '亿', '什', '仅', '仇', '今', '介', '仍', '从', '仔', '他', '付', '仙', '代', '令', '以', '仪', '们', '仰', '件', '价', '任', '份', '仿', '伍', '伏', '休', '众', '优', '伙', '会', '伟', '传', '伤', '伯', '估', '伴', '伸', '似', '但', '位', '低', '住', '体', '何', '余', '佛', '作', '你', '佩', '使', '依', '侧', '侯', '便', '俊', '俗', '保', '信', '修', '倍', '倒', '候', '借', '倩', '值', '倾', '假', '偏', '做', '停', '健', '偷', '傅', '储', '催', '傲', '傻', '像', '儿', '元', '兄', '充', '先', '光', '克', '免', '入', '全', '八', '公', '六', '兮', '兰', '共', '关', '兴', '兵', '其', '具', '典', '养', '兽', '内', '再', '冒', '写', '军', '冥', '冬', '冯', '冰', '冲', '决', '况', '冷', '净', '准', '凉', '凌', '减', '凑', '凝', '几', '凡', '凤', '凭', '凯', '凰', '凶', '出', '击', '刀', '分', '切', '刑', '划', '刘', '则', '刚', '创', '初', '判', '利', '别', '到', '制', '刺', '刻', '前', '剑', '剧', '剩', '副', '劈', '力', '劝', '办', '功', '加', '务', '动', '助', '努', '劫', '劲', '劳', '势', '勇', '勉', '勾', '包', '匆', '化', '北', '区', '医', '十', '千', '升', '午', '半', '华', '单', '卖', '南', '博', '占', '卫', '印', '危', '即', '却', '卷', '厅', '历', '厉', '压', '厚', '原', '厨', '去', '参', '又', '及', '友', '双', '反', '发', '叔', '取', '受', '变', '口', '古', '句', '另', '只', '叫', '可', '台', '史', '右', '叶', '号', '司', '叹', '吃', '各', '合', '吉', '同', '名', '后', '吐', '向', '吓', '吗', '君', '吞', '吟', '否', '吧', '含', '听', '启', '吴', '吸', '吹', '吻', '吼', '呀', '呆', '告', '员', '呢', '周', '味', '呵', '呼', '命', '和', '咔', '咙', '咬', '咱', '咳', '咽', '品', '哈', '响', '哥', '哦', '哪', '哭', '哼', '唇', '唐', '唯', '唰', '商', '啊', '啦', '啪', '啸', '善', '喉', '喊', '喘', '喜', '喝', '喷', '嗯', '嘛', '嘟', '嘲', '嘴', '嘻', '嘿', '噗', '器', '噬', '嚣', '四', '回', '因', '团', '园', '困', '围', '固', '国', '图', '圆', '圈', '土', '圣', '在', '地', '场', '坏', '坐', '块', '坚', '坤', '型', '城', '域', '基', '堂', '堪', '境', '墅', '墓', '墙', '增', '壁', '士', '壮', '声', '处', '备', '复', '夏', '夕', '外', '夙', '多', '夜', '够', '大', '天', '太', '夫', '失', '头', '夹', '夺', '奇', '奈', '奋', '奔', '套', '奥', '女', '奶', '她', '好', '如', '妇', '妈', '妍', '妖', '妙', '妹', '妻', '始', '姐', '姑', '姓', '委', '姿', '威', '娇', '娘', '婆', '婉', '婚', '婷', '媚', '嫁', '嫣', '子', '孔', '字', '存', '孙', '季', '孤', '学', '孩', '宁', '它', '宇', '守', '安', '宋', '完', '宗', '官', '定', '宜', '宝', '实', '客', '室', '宫', '害', '宴', '家', '容', '密', '富', '寒', '察', '寸', '对', '寻', '导', '寿', '封', '射', '将', '尊', '小', '少', '尔', '尖', '尘', '尚', '尝', '尤', '就', '尸', '尽', '尾', '局', '屁', '层', '居', '屈', '屋', '屏', '屑', '展', '属', '山', '岁', '岂', '岛', '岳', '峨', '峰', '崩', '巅', '州', '工', '左', '巧', '巨', '差', '己', '已', '巴', '市', '布', '帅', '师', '希', '帝', '带', '席', '帮', '常', '幕', '干', '平', '年', '并', '幸', '幻', '幽', '广', '庄', '庆', '床', '应', '底', '店', '府', '庞', '废', '度', '座', '庭', '康', '延', '建', '开', '异', '弃', '弄', '式', '引', '弟', '张', '弥', '弯', '弱', '弹', '强', '归', '当', '形', '彩', '影', '彻', '往', '待', '很', '徐', '徒', '得', '御', '微', '德', '心', '必', '忆', '忌', '忍', '志', '忘', '忙', '忠', '忧', '快', '念', '忽', '怀', '态', '怎', '怒', '怕', '怖', '怜', '思', '怡', '急', '性', '怨', '怪', '总', '恐', '恒', '恢', '恨', '恩', '恭', '息', '恶', '恼', '悄', '悉', '悍', '悔', '悟', '悠', '悦', '您', '悲', '情', '惊', '惑', '惜', '惧', '惨', '惯', '想', '惹', '意', '感', '愣', '愤', '愧', '愿', '慌', '慕', '慢', '慰', '憋', '懂', '懒', '戏', '成', '我', '戒', '或', '战', '戴', '户', '房', '所', '扇', '手', '才', '扎', '扑', '打', '扔', '托', '扣', '执', '扫', '扬', '扭', '扯', '扰', '扶', '批', '找', '承', '技', '把', '抓', '投', '抖', '抗', '折', '抢', '护', '报', '抬', '抱', '抵', '抹', '抽', '担', '拉', '拍', '拒', '拔', '拖', '招', '拜', '拥', '拦', '择', '拳', '拼', '拾', '拿', '持', '挂', '指', '按', '挑', '挡', '挣', '挤', '挥', '挺', '捏', '捕', '损', '换', '据', '掉', '掌', '排', '掠', '探', '接', '控', '推', '掩', '提', '插', '握', '搂', '搞', '摆', '摇', '摔', '摸', '撇', '撑', '撕', '撞', '擂', '操', '擦', '支', '收', '改', '攻', '放', '政', '故', '效', '敌', '敏', '救', '教', '敢', '散', '敬', '数', '敲', '整', '文', '斗', '料', '斥', '斩', '断', '斯', '新', '方', '施', '旁', '旋', '族', '无', '既', '日', '旦', '旧', '早', '时', '明', '昏', '易', '星', '春', '昨', '是', '显', '晃', '晋', '晓', '晕', '晚', '晨', '普', '景', '晴', '晶', '智', '暂', '暖', '暗', '暮', '暴', '曲', '更', '曾', '替', '最', '月', '有', '朋', '服', '望', '朝', '期', '木', '未', '末', '本', '术', '朱', '朵', '机', '杀', '杂', '权', '李', '材', '杜', '束', '条', '来', '杨', '杯', '杰', '松', '板', '极', '林', '枚', '果', '枪', '枫', '架', '柄', '某', '染', '柔', '查', '柱', '柳', '标', '树', '校', '样', '核', '根', '格', '案', '桌', '梁', '梅', '梦', '检', '森', '椅', '楚', '楼', '槃', '模', '横', '次', '欢', '欣', '欧', '欲', '欺', '歉', '止', '正', '此', '步', '武', '死', '殊', '残', '段', '殿', '毁', '毅', '母', '每', '毒', '比', '毕', '毛', '毫', '民', '气', '氛', '水', '永', '求', '汇', '汉', '汗', '江', '池', '汤', '汹', '沈', '沉', '沌', '沙', '没', '河', '油', '治', '泄', '泉', '法', '泛', '泡', '波', '泥', '注', '泪', '泽', '洁', '洋', '洒', '洗', '洛', '洞', '洪', '洲', '活', '派', '流', '测', '浑', '浓', '浩', '浪', '浮', '海', '涅', '消', '涌', '涛', '润', '涨', '液', '淡', '深', '混', '清', '渐', '渡', '温', '港', '游', '湖', '源', '滋', '滚', '满', '滴', '漂', '漆', '演', '漠', '漫', '潜', '潮', '激', '火', '灭', '灯', '灰', '灵', '炎', '炸', '点', '炼', '烁', '烂', '烈', '烟', '烦', '烧', '热', '焦', '焰', '然', '煞', '照', '熊', '熟', '燃', '燕', '爆', '爪', '爬', '爱', '父', '爷', '爸', '爽', '片', '牌', '牙', '牛', '牢', '物', '牵', '特', '犯', '状', '犹', '狂', '狐', '狗', '狠', '独', '狮', '狱', '狼', '猛', '猜', '猪', '猫', '猴', '玄', '率', '玉', '王', '玩', '环', '现', '玲', '珊', '珍', '珠', '班', '球', '理', '琴', '瑶', '璃', '瓶', '甄', '甘', '甚', '生', '用', '甩', '田', '由', '甲', '电', '男', '画', '界', '畏', '留', '略', '番', '疑', '疗', '疤', '疯', '疼', '病', '痕', '痛', '瘦', '白', '百', '的', '皇', '皓', '皮', '皱', '盈', '益', '盖', '盘', '盛', '盟', '目', '盯', '直', '相', '省', '眉', '看', '真', '眨', '眯', '眸', '眼', '着', '睁', '睛', '睡', '瞧', '瞪', '瞬', '知', '短', '石', '码', '砍', '研', '砰', '破', '砸', '硬', '确', '碎', '碰', '磨', '示', '礼', '社', '祖', '神', '祥', '祸', '禁', '福', '离', '秀', '私', '秋', '种', '科', '秒', '秘', '秦', '积', '称', '移', '程', '稍', '稳', '究', '穷', '空', '穿', '突', '窗', '立', '站', '竟', '章', '端', '笑', '笔', '符', '第', '笼', '等', '筋', '答', '简', '算', '管', '箭', '篮', '米', '类', '粉', '粗', '精', '糊', '糖', '系', '素', '索', '紧', '紫', '累', '红', '约', '级', '纪', '纯', '纵', '纷', '纸', '纹', '线', '练', '组', '细', '织', '终', '绍', '经', '结', '绕', '给', '绝', '统', '继', '绪', '续', '维', '绾', '绿', '缓', '缘', '缠', '缩', '缺', '网', '罗', '罡', '罢', '罩', '罪', '置', '美', '羞', '群', '羽', '翘', '翻', '翼', '耀', '老', '考', '者', '而', '耍', '耐', '耗', '耳', '耸', '耻', '聊', '职', '联', '聚', '聪', '肃', '肆', '肉', '肌', '肚', '股', '肤', '肩', '肯', '胁', '胆', '背', '胖', '胜', '胡', '胳', '胸', '能', '脆', '脉', '脏', '脑', '脖', '脚', '脱', '脸', '腰', '腾', '腿', '膀', '臂', '自', '臭', '至', '致', '舌', '舍', '舒', '舞', '舟', '般', '船', '良', '色', '艳', '艺', '节', '芒', '花', '芳', '芸', '苍', '苏', '若', '苦', '英', '茂', '范', '茜', '茫', '茶', '茹', '草', '荒', '荡', '荣', '药', '莫', '莲', '获', '莹', '菜', '菲', '营', '萧', '萱', '落', '董', '蒙', '蓝', '蕴', '薄', '薇', '薛', '藏', '虎', '虑', '虚', '虫', '虽', '蛇', '蛋', '蛮', '融', '蟒', '血', '行', '街', '衣', '补', '表', '衫', '袁', '袋', '袍', '被', '袭', '裂', '装', '西', '要', '覆', '见', '观', '规', '视', '觉', '角', '解', '触', '言', '警', '计', '认', '讨', '让', '训', '议', '记', '讲', '讶', '许', '论', '讽', '设', '诀', '证', '识', '诉', '试', '诗', '诚', '话', '诡', '该', '语', '误', '诱', '说', '请', '诸', '课', '谁', '调', '谈', '谋', '谓', '谢', '谷', '象', '豪', '豫', '豹', '貌', '负', '财', '责', '败', '货', '质', '贴', '贵', '费', '资', '赋', '赌', '赏', '赛', '赞', '赢', '赤', '走', '赵', '赶', '起', '趁', '超', '越', '趟', '趣', '足', '跃', '跑', '距', '跟', '跨', '跪', '路', '跳', '踏', '踢', '踩', '踪', '身', '躯', '躲', '躺', '车', '轩', '转', '轮', '软', '轰', '轻', '较', '辆', '辈', '辉', '输', '辕', '辣', '辰', '辱', '边', '达', '过', '迎', '运', '近', '还', '这', '进', '远', '连', '迟', '迫', '迷', '迹', '追', '退', '送', '适', '逃', '逆', '选', '逍', '透', '逐', '递', '途', '通', '速', '造', '逼', '遇', '遍', '道', '遗', '遥', '遭', '遮', '避', '那', '邪', '邹', '郁', '郑', '部', '都', '配', '酒', '醉', '醒', '采', '释', '里', '重', '野', '量', '金', '针', '钟', '钢', '钱', '钻', '铁', '银', '锁', '锋', '锐', '错', '镇', '镖', '镜', '长', '门', '闪', '闭', '问', '闯', '闲', '间', '闷', '闹', '闻', '阁', '队', '防', '阳', '阴', '阵', '阶', '阻', '阿', '附', '际', '陆', '陈', '降', '限', '陡', '院', '除', '险', '陪', '陶', '陷', '隆', '随', '隐', '隔', '难', '雁', '雄', '雅', '集', '雨', '雪', '零', '雷', '雾', '需', '霄', '震', '霍', '霜', '霞', '露', '霸', '青', '静', '非', '靠', '面', '韩', '音', '韵', '顶', '项', '顺', '须', '顾', '顿', '预', '领', '颗', '题', '颜', '额', '颤', '风', '飘', '飞', '食', '餐', '饭', '饶', '馆', '首', '香', '马', '驶', '驾', '骂', '骄', '验', '骑', '骗', '骨', '高', '鬼', '魂', '魄', '魏', '魔', '鱼', '鲜', '鸟', '鸡', '鸣', '鸿', '鹏', '鹤', '鹰', '麻', '黄', '黑', '默', '鼎', '鼓', '鼻', '齐', '齿', '龙']\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "\n",
    "words_file_path = \"vocab.txt\"\n",
    "\n",
    "words_file = codecs.open(words_file_path, 'w', encoding='gbk')\n",
    "# hugeStr = \"\".join(str(words))\n",
    "# words_file.write(hugeStr)\n",
    "\n",
    "for w in words:\n",
    "    if w != \"\\n\":\n",
    "        words_file.write(w)\n",
    "        words_file.write(\"\\n\")\n",
    "\n",
    "words_file.close()\n",
    "\n",
    "print(words)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences ignored:  21374058\n",
      "Number of remaining sequences:  2174305\n",
      "Runtime for this cell in seconds:  80.92613506317139\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "seqLen = 45\n",
    "step = 1\n",
    "sequences = []\n",
    "nextWords = []\n",
    "seqIgnored = 0\n",
    "for i in range(0, len(allTokens) - seqLen, step):\n",
    "    if len(set(allTokens[i:i+seqLen+1]).intersection(skipWords)) == 0:\n",
    "        sequences.append(allTokens[i:i + seqLen])\n",
    "        nextWords.append(allTokens[i + seqLen])\n",
    "    else:\n",
    "        seqIgnored += 1\n",
    "\n",
    "print(\"Number of sequences ignored: \", seqIgnored)\n",
    "print(\"Number of remaining sequences: \", len(sequences))\n",
    "\n",
    "t2 = time.time()\n",
    "print(\"Runtime for this cell in seconds: \", t2 - t1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled and split sentences\n",
      "Size of training set = 1739444\n",
      "Size of test set = 434861\n"
     ]
    }
   ],
   "source": [
    "# def shuffle_and_split_training_set(sentences_original, next_original, percentage_test=20):\n",
    "#     # shuffle at unison\n",
    "#     print('Shuffling sentences')\n",
    "#\n",
    "#     tmp_sentences = []\n",
    "#     tmp_next_word = []\n",
    "#\n",
    "#     for i in np.random.permutation(len(sentences_original)):\n",
    "#         tmp_sentences.append(sentences_original[i])\n",
    "#         tmp_next_word.append(next_original[i])\n",
    "#\n",
    "#     cut_index = int(len(sentences_original) * (1.-(percentage_test/100.)))\n",
    "#     x_train, x_test = tmp_sentences[:cut_index], tmp_sentences[cut_index:]\n",
    "#     y_train, y_test = tmp_next_word[:cut_index], tmp_next_word[cut_index:]\n",
    "#\n",
    "#     print(\"Size of training set = %d\" % len(x_train))\n",
    "#     print(\"Size of test set = %d\" % len(y_test))\n",
    "#     return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "sentences, testSentences, nextWordsTrain, testNextWords = train_test_split(sequences, nextWords, test_size=0.2, shuffle=True)\n",
    "print(\"Shuffled and split sentences\")\n",
    "print(\"Size of training set = \" + str(len(sentences)))\n",
    "print(\"Size of test set = \" + str(len(testSentences)))\n",
    "\n",
    "tr = 0\n",
    "te = 0\n",
    "for word in words:\n",
    "    if word not in nextWordsTrain:\n",
    "        print(word)\n",
    "    elif word not in testNextWords:\n",
    "        print(word)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr:  1699\n",
      "te:  1699\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['势', '在', '不', '断', '的', '增', '高', '这', '一', '发', '现', '让', '叶', '晨', '峰', '心', '里', '面', '有', '底', '了', '这', '也', '就', '证', '明', '叶', '晨', '峰', '他', '们', '在', '往', '高', '处', '奔', '跑', '只', '要', '奔', '跑', '到', '这', '条', '道'], ['议', '让', '雷', '正', '阳', '参', '加', '这', '一', '次', '的', '行', '动', '因', '为', '他', '一', '刀', '斩', '杀', '兽', '化', '的', '冷', '风', '就', '已', '经', '展', '现', '出', '强', '大', '的', '实', '力', '现', '在', '正', '是', '需', '要', '帮', '手', '的'], ['白', '琴', '能', '不', '惊', '讶', '吗', '这', '可', '是', '她', '一', '直', '躲', '避', '甚', '至', '想', '都', '不', '敢', '想', '的', '事', '现', '在', '却', '要', '去', '面', '对', '白', '琴', '还', '没', '有', '做', '好', '这', '个', '准', '备', '呢', '也', '许'], ['让', '我', '去', '核', '查', '资', '料', '开', '玩', '笑', '小', '学', '毕', '业', '后', '我', '就', '很', '少', '用', '脑', '子', '了', '石', '林', '笑', '着', '说', '道', '既', '然', '张', '舒', '君', '想', '利', '用', '他', '跟', '他', '玩', '阴', '的', '那', '石'], ['在', '法', '则', '感', '悟', '上', '赶', '上', '渡', '劫', '期', '修', '士', '要', '多', '花', '费', '不', '知', '道', '多', '少', '倍', '的', '时', '间', '和', '精', '力', '甚', '至', '比', '突', '破', '渡', '劫', '期', '然', '后', '再', '领', '悟', '法', '则', '花'], ['的', '实', '力', '也', '只', '提', '升', '到', '了', '先', '天', '巅', '峰', '的', '层', '次', '曾', '经', '他', '从', '来', '没', '想', '过', '自', '己', '会', '和', '顶', '级', '势', '力', '这', '边', '的', '四', '大', '门', '派', '有', '任', '何', '的', '交', '集'], ['觉', '到', '黑', '色', '巨', '虎', '和', '这', '女', '子', '都', '不', '是', '省', '油', '的', '灯', '虽', '然', '他', '们', '应', '该', '都', '受', '了', '严', '重', '的', '伤', '势', '但', '根', '据', '他', '们', '的', '气', '势', '来', '判', '断', '这', '黑', '色'], ['好', '人', '而', '且', '我', '一', '看', '到', '警', '察', '就', '觉', '的', '亲', '近', '怎', '么', '会', '做', '出', '让', '你', '们', '为', '难', '的', '事', '情', '呢', '我', '知', '道', '这', '都', '是', '谢', '老', '头', '儿', '谢', '局', '长', '的', '意', '思'], ['问', '王', '河', '睡', '在', '客', '厅', '沙', '发', '上', '冷', '不', '冷', '舒', '服', '不', '舒', '服', '而', '三', '个', '女', '孩', '呢', '在', '里', '面', '笑', '声', '也', '大', '的', '惊', '人', '弄', '得', '王', '河', '实', '在', '受', '不', '了', '只', '好'], ['这', '些', '日', '子', '不', '太', '好', '去', '拳', '馆', '所', '以', '就', '回', '到', '特', '事', '处', '三', '组', '办', '公', '室', '了', '你', '要', '来', '吗', '沈', '月', '的', '声', '音', '很', '欢', '快', '听', '到', '苏', '辰', '打', '电', '话', '她', '似']]\n",
      "['路', '时', '她', '林', '的', '的', '巨', '你', '跑', '乎']\n"
     ]
    }
   ],
   "source": [
    "print(testSentences[:10])\n",
    "print(testNextWords[:10])\n",
    "\n",
    "sentences_train = \"sentences_train.txt\"\n",
    "nextWords_train = \"nextWords_train.txt\"\n",
    "sentences_tests = \"sentences_tests.txt\"\n",
    "nextWords_tests = \"nextWords_tests.txt\"\n",
    "\n",
    "with open(sentences_train, \"w\", encoding='gbk') as sentences_file:\n",
    "    for sentence in sentences:\n",
    "        tmp_sentence = \",\".join(sentence)\n",
    "        sentences_file.write(f\"{tmp_sentence}\\n\")\n",
    "\n",
    "with open(sentences_tests, \"w\", encoding='gbk') as sentences_tests_file:\n",
    "    for sentence in testSentences:\n",
    "        tmp_sentence = \",\".join(sentence)\n",
    "        sentences_tests_file.write(f\"{tmp_sentence}\\n\")\n",
    "\n",
    "with open(nextWords_train, \"w\", encoding='gbk') as nextWords_testFile:\n",
    "    for nextword in nextWordsTrain:\n",
    "        nextWords_testFile.write(f\"{nextword}\\n\")\n",
    "\n",
    "with open(nextWords_tests, \"w\", encoding='gbk') as nextWords_testFile:\n",
    "    for nextword in testNextWords:\n",
    "        nextWords_testFile.write(f\"{nextword}\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
